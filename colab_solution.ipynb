{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/beruscoder/Bhatiyani-Astute-Intelligence-assignment/blob/main/colab_solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DnYosZ8RCQ4s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b830205a-98e2-4962-8bb5-511e56d4d7b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/207.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m207.2/207.2 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -U ultralytics supervision opencv-python-headless -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85-Tf1a8CW9x",
        "outputId": "b7caedc0-e7b2-474f-af34-13a591668a1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ‚úÖ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8s.pt to 'yolov8s.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21.5MB 229.0MB/s 0.1s\n",
            "Processed 100 frames | In:5 Out:1 Active:4 | Time: 6.3s\n",
            "Processed 200 frames | In:8 Out:5 Active:3 | Time: 10.9s\n",
            "Processed 300 frames | In:12 Out:10 Active:2 | Time: 16.2s\n",
            "‚úÖ Finished. Final counts => In: 16, Out: 12\n",
            "üé• Output saved to: /content/output_person_roi.avi\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================\n",
        "# Footfall Counter with ROI Polygon + Trajectories + Heatmap\n",
        "# (YOLOv8 + ByteTrack + Supervision)\n",
        "# --------------------------------------------------------------\n",
        "# Author : Jansty Lewis\n",
        "# Description : Detect, track, and count people entering/exiting\n",
        "#               a defined Region of Interest (ROI) using YOLOv8.\n",
        "# ==============================================================\n",
        "\n",
        "# Install dependencies (uncomment if running in Colab)\n",
        "# !pip install -U ultralytics supervision opencv-python-headless -q\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# Imports\n",
        "# --------------------------------------------------------------\n",
        "import time\n",
        "import cv2\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "from ultralytics import YOLO\n",
        "import supervision as sv\n",
        "\n",
        "\n",
        "# ==============================================================\n",
        "# 1Ô∏è‚É£ Helper Class ‚Äî Centroid Smoothing\n",
        "# --------------------------------------------------------------\n",
        "# Smoothens object centroids to reduce flickering and noise\n",
        "# when computing trajectories and heatmaps.\n",
        "# ==============================================================\n",
        "class CentroidSmoother:\n",
        "    def __init__(self, alpha=0.6):\n",
        "        \"\"\"\n",
        "        alpha : float\n",
        "            Smoothing factor (0 < alpha <= 1).\n",
        "            Higher alpha = faster response, less smoothing.\n",
        "        \"\"\"\n",
        "        self.alpha = alpha\n",
        "        self.states = {}  # Stores smoothed coordinates {id: (x, y)}\n",
        "\n",
        "    def smooth(self, tid, cx, cy):\n",
        "        \"\"\"Applies exponential moving average smoothing to centroid.\"\"\"\n",
        "        if tid not in self.states:\n",
        "            self.states[tid] = (cx, cy)\n",
        "            return cx, cy\n",
        "\n",
        "        px, py = self.states[tid]\n",
        "        nx = int(self.alpha * cx + (1 - self.alpha) * px)\n",
        "        ny = int(self.alpha * cy + (1 - self.alpha) * py)\n",
        "        self.states[tid] = (nx, ny)\n",
        "        return nx, ny\n",
        "\n",
        "\n",
        "# ==============================================================\n",
        "# 2Ô∏è‚É£ Utility Functions\n",
        "# --------------------------------------------------------------\n",
        "# Contains helper logic for counting, drawing, and visualization.\n",
        "# ==============================================================\n",
        "\n",
        "def define_roi_polygon(out_w, out_h):\n",
        "    \"\"\"Define polygonal Region of Interest (ROI). Modify as needed.\"\"\"\n",
        "    polygon = np.array([\n",
        "        [150, int(out_h * 0.7)],\n",
        "        [out_w - 150, int(out_h * 0.7)],\n",
        "        [out_w - 150, out_h - 20],\n",
        "        [150, out_h - 20]\n",
        "    ])\n",
        "    return polygon\n",
        "\n",
        "\n",
        "def update_counting_state(\n",
        "    tid, sx, sy, polygon, last_state, last_count_time,\n",
        "    count_in, count_out, count_cooldown\n",
        "):\n",
        "    \"\"\"\n",
        "    Determines whether an object has entered or exited the ROI\n",
        "    and updates counts accordingly.\n",
        "    \"\"\"\n",
        "    inside = cv2.pointPolygonTest(polygon, (sx, sy), False) >= 0\n",
        "    prev_state = last_state.get(tid, \"outside\")\n",
        "    current_state = \"inside\" if inside else \"outside\"\n",
        "    now = time.time()\n",
        "\n",
        "    if prev_state != current_state:\n",
        "        # Check cooldown to avoid multiple triggers\n",
        "        if now - last_count_time[tid] > count_cooldown:\n",
        "            if prev_state == \"outside\" and current_state == \"inside\":\n",
        "                count_in += 1\n",
        "            elif prev_state == \"inside\" and current_state == \"outside\":\n",
        "                count_out += 1\n",
        "            last_count_time[tid] = now\n",
        "\n",
        "    last_state[tid] = current_state\n",
        "    return current_state, count_in, count_out\n",
        "\n",
        "\n",
        "def draw_trajectories(frame, traces):\n",
        "    \"\"\"Draw trajectory lines for each tracked object.\"\"\"\n",
        "    for tid, pts in traces.items():\n",
        "        if len(pts) > 1:\n",
        "            for i in range(1, len(pts)):\n",
        "                cv2.line(frame, pts[i - 1], pts[i], (0, 255, 255), 2)\n",
        "    return frame\n",
        "\n",
        "\n",
        "def overlay_heatmap(base_frame, heatmap):\n",
        "    \"\"\"Generate and overlay the heatmap on top of the base frame.\"\"\"\n",
        "    blur = cv2.GaussianBlur(heatmap, (35, 35), 0)\n",
        "    norm = cv2.normalize(blur, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
        "    colored = cv2.applyColorMap(norm, cv2.COLORMAP_JET)\n",
        "    overlay = cv2.addWeighted(base_frame, 0.8, colored, 0.4, 0)\n",
        "    return overlay\n",
        "\n",
        "\n",
        "def draw_info_overlay(frame, count_in, count_out, active_inside):\n",
        "    \"\"\"Displays live statistics (In/Out/Active) on the frame.\"\"\"\n",
        "    cv2.putText(frame, f\"In: {count_in}\", (10, 30),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
        "    cv2.putText(frame, f\"Out: {count_out}\", (10, 70),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
        "    cv2.putText(frame, f\"Active (inside): {active_inside}\", (10, 110),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
        "    return frame\n",
        "\n",
        "\n",
        "# ==============================================================\n",
        "# 3Ô∏è‚É£ Main Function ‚Äî Tracking + Counting + Visualization\n",
        "# ==============================================================\n",
        "def track_and_count_persons_roi(\n",
        "    source=\"mall.mp4\",\n",
        "    output_path=\"output_person_roi.avi\",\n",
        "    model_name=\"yolov8s.pt\",\n",
        "    resize_width=None,\n",
        "    conf=0.35,\n",
        "    classes=[0],  # Person class\n",
        "):\n",
        "    \"\"\"\n",
        "    Core function to perform:\n",
        "    - Object detection using YOLOv8\n",
        "    - Tracking using ByteTrack\n",
        "    - ROI-based entry/exit counting\n",
        "    - Trajectory and heatmap visualization\n",
        "    \"\"\"\n",
        "    # ------------------- Initialization ------------------------\n",
        "    model = YOLO(model_name)\n",
        "    tracker = sv.ByteTrack()\n",
        "    box_annotator = sv.BoxAnnotator(thickness=2)\n",
        "    label_annotator = sv.LabelAnnotator()\n",
        "\n",
        "    cap = cv2.VideoCapture(source)\n",
        "    if not cap.isOpened():\n",
        "        raise RuntimeError(f\"Could not open video: {source}\")\n",
        "\n",
        "    W, H = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS) or 25.0\n",
        "\n",
        "    # Resize settings\n",
        "    if resize_width is not None:\n",
        "        scale = resize_width / float(W)\n",
        "        out_w, out_h = int(resize_width), int(H * scale)\n",
        "    else:\n",
        "        out_w, out_h, scale = W, H, 1.0\n",
        "\n",
        "    # Output video writer\n",
        "    fourcc = cv2.VideoWriter_fourcc(*\"XVID\")\n",
        "    writer = cv2.VideoWriter(output_path, fourcc, fps, (out_w, out_h))\n",
        "\n",
        "    # ------------------- ROI & Annotations ----------------------\n",
        "    polygon = define_roi_polygon(out_w, out_h)\n",
        "    zone = sv.PolygonZone(polygon=polygon)\n",
        "    zone_annotator = sv.PolygonZoneAnnotator(\n",
        "        zone=zone, color=sv.Color.from_hex(\"#0000FF\"),\n",
        "        thickness=2, text_thickness=2, text_scale=1\n",
        "    )\n",
        "\n",
        "    # ------------------- Tracking State -------------------------\n",
        "    smoother = CentroidSmoother(alpha=0.6)\n",
        "    traces = defaultdict(list)\n",
        "    heatmap = np.zeros((out_h, out_w), dtype=np.float32)\n",
        "\n",
        "    last_state = {}\n",
        "    last_count_time = defaultdict(lambda: -9999)\n",
        "    count_cooldown = 0.8\n",
        "    count_in, count_out = 0, 0\n",
        "\n",
        "    frame_idx, start_ts = 0, time.time()\n",
        "\n",
        "    # ==========================================================\n",
        "    # Frame-by-Frame Processing\n",
        "    # ==========================================================\n",
        "    try:\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "            frame_idx += 1\n",
        "\n",
        "            # Resize (if required)\n",
        "            frame_resized = cv2.resize(frame, (out_w, out_h)) if resize_width else frame.copy()\n",
        "\n",
        "            # ---------------- Detection & Tracking ----------------\n",
        "            results = model.predict(source=[frame_resized], imgsz=640, conf=conf, classes=classes, verbose=False)\n",
        "            detections = sv.Detections.from_ultralytics(results[0])\n",
        "            tracked = tracker.update_with_detections(detections)\n",
        "\n",
        "            # ---------------- Visualization ------------------------\n",
        "            labels = [f\"person {int(tid)}\" for tid in getattr(tracked, \"tracker_id\", [])]\n",
        "            annotated = box_annotator.annotate(scene=frame_resized.copy(), detections=tracked)\n",
        "            if labels:\n",
        "                annotated = label_annotator.annotate(scene=annotated, detections=tracked, labels=labels)\n",
        "            annotated = zone_annotator.annotate(scene=annotated)\n",
        "\n",
        "            # ---------------- Counting Logic -----------------------\n",
        "            current_inside = set()\n",
        "            tracked_xyxy, tracked_ids = getattr(tracked, \"xyxy\", []), getattr(tracked, \"tracker_id\", [])\n",
        "\n",
        "            if tracked_xyxy is not None and len(tracked_xyxy) > 0:\n",
        "                for bb, tid in zip(tracked_xyxy, tracked_ids):\n",
        "                    x1, y1, x2, y2 = bb\n",
        "                    cx, cy = int((x1 + x2) / 2), int((y1 + y2) / 2)\n",
        "                    sx, sy = smoother.smooth(int(tid), cx, cy)\n",
        "                    traces[tid].append((sx, sy))\n",
        "                    cv2.circle(heatmap, (sx, sy), 8, 1, -1)\n",
        "\n",
        "                    current_state, count_in, count_out = update_counting_state(\n",
        "                        tid, sx, sy, polygon, last_state, last_count_time,\n",
        "                        count_in, count_out, count_cooldown\n",
        "                    )\n",
        "\n",
        "                    if current_state == \"inside\":\n",
        "                        current_inside.add(tid)\n",
        "\n",
        "            active_inside = len(current_inside)\n",
        "\n",
        "            # ---------------- Overlays -----------------------------\n",
        "            annotated = draw_trajectories(annotated, traces)\n",
        "            overlay = overlay_heatmap(annotated, heatmap)\n",
        "            overlay = draw_info_overlay(overlay, count_in, count_out, active_inside)\n",
        "\n",
        "            # Write frame\n",
        "            writer.write(overlay)\n",
        "\n",
        "            # Progress log\n",
        "            if frame_idx % 100 == 0:\n",
        "                elapsed = time.time() - start_ts\n",
        "                print(f\"Processed {frame_idx} frames | In:{count_in} Out:{count_out} Active:{active_inside} | Time: {elapsed:.1f}s\")\n",
        "\n",
        "    finally:\n",
        "        cap.release()\n",
        "        writer.release()\n",
        "        print(f\"‚úÖ Finished. Final counts => In: {count_in}, Out: {count_out}\")\n",
        "        print(f\"üé• Output saved to: {output_path}\")\n",
        "\n",
        "\n",
        "# ==============================================================\n",
        "# 4Ô∏è‚É£ Example Entry Point (For Google Colab)\n",
        "# ==============================================================\n",
        "if __name__ == \"__main__\":\n",
        "    track_and_count_persons_roi(\n",
        "        source=\"/content/walking.mp4\",\n",
        "        output_path=\"/content/output_person_roi.avi\",\n",
        "        model_name=\"yolov8s.pt\",\n",
        "        resize_width=640,\n",
        "        conf=0.35\n",
        "    )\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyN0uaMNOCbonKJaH30LL/g9",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}